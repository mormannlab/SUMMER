{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', )))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from config_colors import *\n",
    "from config_paths import *\n",
    "from config_plot_params import *\n",
    "from nwb_io import *\n",
    "\n",
    "from tabulate import tabulate\n",
    "from nilearn.plotting import plot_markers\n",
    "\n",
    "import visualization.plot_code.spike_sorting.utils.binning_isolated_from_db as binning\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', '{:.8f}'.format)\n",
    "\n",
    "# save panels directly to the relevant svg/ subdir\n",
    "panel_save_dir = Path.cwd().parent.parent / \"figure_generation\" / \"figure_spike_sorting\" / \"svg\"\n",
    "\n",
    "\n",
    "data_dir = NWB_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45a0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdivide = None\n",
    "small_bin_length = None\n",
    "bin_length = 1000\n",
    "\n",
    "pat_subset = np.arange(1,29+1)\n",
    "\n",
    "i=0\n",
    "\n",
    "units_per_channel = []\n",
    "region_for_channel = []\n",
    "\n",
    "for patient_id in pat_subset:\n",
    "\n",
    "    path = data_dir / f\"sub{patient_id}.nwb\"\n",
    "    print(f\"  {patient_id}\")\n",
    "    io = NWBHDF5IO(path, mode=\"r\")\n",
    "    nwbfile = io.read()\n",
    "\n",
    "    print(\"  converting spikes to dataframe..\")\n",
    "    df_units = nwbfile.units.to_dataframe()\n",
    "    df_units[\"unit_id\"] = np.arange(0, len(df_units))\n",
    "\n",
    "    df_units.insert(0, \"patient_id\", [patient_id] * len(df_units), )\n",
    "\n",
    "    ### calculate firing rate\n",
    "    movie_edges_all = nwbfile.processing[\"misc\"].data_interfaces[\"movie_binning_info\"].to_dataframe()\n",
    "    movie_edges = movie_edges_all[movie_edges_all[\"bin_length\"] == bin_length][\"edges\"].iloc[0]\n",
    "\n",
    "    spikes = df_units[\"spike_times\"]\n",
    "\n",
    "    wl = nwbfile.stimulus[\"cleaned_watchlogs\"].to_dataframe()\n",
    "    patient_rec = wl[\"neural_recording_time\"].to_numpy()\n",
    "    patient_pts = wl[\"pts\"].to_numpy()\n",
    "\n",
    "    res = binning.bin_spikes_with_movie_edges(bin_length, spikes, movie_edges, patient_rec, patient_pts, subdivide, small_bin_length)\n",
    "    \n",
    "    fr_hz = np.mean(res, axis=1)\n",
    "    df_units.insert(len(df_units.columns) - 1, \"fr_hz\", fr_hz)\n",
    "    ###\n",
    "\n",
    "    ### grab number of units per channel\n",
    "    channel_names = nwbfile.electrode_groups.keys()\n",
    "    nm_total_channels = len(channel_names) * 8\n",
    "\n",
    "    electrode_df = nwbfile.electrodes.to_dataframe()\n",
    "\n",
    "    for id, row in electrode_df.iterrows():\n",
    "        csc_nr = row.csc_nr\n",
    "        brain_region = row.brain_region\n",
    "\n",
    "        mask = df_units[\"csc_nr\"] == csc_nr\n",
    "        filtered_df = df_units[mask]\n",
    "        nm_units_in_channel = len(filtered_df)\n",
    "\n",
    "        units_per_channel.append(nm_units_in_channel)\n",
    "        region_for_channel.append(brain_region)\n",
    "    ###\n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        df_units_all = df_units.copy()\n",
    "    else:\n",
    "        df_units_all = pd.concat([df_units_all, df_units], ignore_index=True)\n",
    "    \n",
    "    io.close()\n",
    "    i += 1\n",
    "\n",
    "\n",
    "\n",
    "df_units_all = df_units_all[df_units_all[\"brain_region\"] != \"I\"]\n",
    "df_units_all = df_units_all[df_units_all[\"brain_region\"] != \"T\"]\n",
    "df_units_all[\"brain_region\"] = df_units_all[\"brain_region\"].replace([\"AH\", \"MH\", \"PH\"], \"H\",)\n",
    "\n",
    "\n",
    "units_per_channel = np.array(units_per_channel)\n",
    "region_for_channel = np.array(region_for_channel)\n",
    "\n",
    "df_channelwise_units = pd.DataFrame({\n",
    "    \"channel_count\": units_per_channel,\n",
    "    \"channel_region\": region_for_channel, \n",
    "})\n",
    "\n",
    "df_channelwise_units[\"channel_region\"] = df_channelwise_units[\"channel_region\"].replace([\"AH\", \"MH\", \"PH\"], \"H\",)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f366e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channelwise_units[\"channel_region\"] = df_channelwise_units[\"channel_region\"].replace({\n",
    "    \"PIC\": \"Other\",\n",
    "    \"FF\": \"Other\",\n",
    "    \"LG\": \"Other\",\n",
    "    \"FF\": \"Other\",\n",
    "    \"PRC\": \"Other\",\n",
    "})\n",
    "\n",
    "df_units_all[\"brain_region\"] = df_units_all[\"brain_region\"].replace({\n",
    "    \"PIC\": \"Other\",\n",
    "    \"FF\": \"Other\",\n",
    "    \"LG\": \"Other\",\n",
    "    \"FF\": \"Other\",\n",
    "    \"PRC\": \"Other\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot params\n",
    "\n",
    "lw_cdf = 3\n",
    "lw_summary_stat = 3\n",
    "b = 25\n",
    "\n",
    "stat_line_color = \"dimgrey\"\n",
    "\n",
    "title_size_subplot = 16\n",
    "label_size = 14\n",
    "tick_size = 10\n",
    "\n",
    "# data processing \n",
    "\n",
    "## units per channel\n",
    "def channelwise_hists_for_a_region(df_channelwise_units, region, bins):\n",
    "    mask = df_channelwise_units[\"channel_region\"] == region\n",
    "    region_channels = df_channelwise_units[mask]\n",
    "    hists, _ = np.histogram(region_channels[\"channel_count\"].to_numpy(), bins)\n",
    "    return hists\n",
    "\n",
    "def cdf_regionwise_channels(df_channelwise_units, bins):\n",
    "    regions = np.unique(df_channelwise_units[\"channel_region\"])\n",
    "    return {r: apply_cdf(channelwise_hists_for_a_region(df_channelwise_units, r, bins)) for r in regions}\n",
    "\n",
    "def data_units_per_channel(df_channelwise_units, bins=25):\n",
    "    hist, bin_edges = np.histogram(df_channelwise_units[\"channel_count\"], bins)\n",
    "\n",
    "    regions_cdf_dict = cdf_regionwise_channels(df_channelwise_units, bins)\n",
    "    return hist, bin_edges, regions_cdf_dict\n",
    "\n",
    "\n",
    "## other metrics/amounts\n",
    "def filter_df_column_by_region(df_units_all: pd.DataFrame, column: str, region: str, bins: int, log: bool):\n",
    "    mask = df_units_all[\"brain_region\"] == region\n",
    "    df_region_restricted = df_units_all[mask]\n",
    "\n",
    "    nan_mask = ~np.isnan(df_region_restricted[column])\n",
    "    df_region_data = df_region_restricted[nan_mask]\n",
    "\n",
    "    if log: \n",
    "        data = np.log10(df_region_data[column])\n",
    "    else:\n",
    "        data = df_region_data[column].to_numpy()\n",
    "\n",
    "    hists, _ = np.histogram(data, bins)\n",
    "    return hists\n",
    "\n",
    "def cdf_regionwise_metrics(df_units_all, column, bins, log=False):\n",
    "    regions = np.unique(df_units_all[\"brain_region\"])\n",
    "    return {r: apply_cdf(filter_df_column_by_region(df_units_all, column, r, bins, log)) for r in regions}\n",
    "\n",
    "def no_nan_histogram(metric_array, b):\n",
    "    data = metric_array[~np.isnan(metric_array)]\n",
    "    hists, bin_edges = np.histogram(data, b)\n",
    "    return hists, bin_edges\n",
    "\n",
    "def count_su_mu(df_units_all):\n",
    "    su = sum(df_units_all[\"is_single_unit\"])\n",
    "    mu = len(df_units_all) - su\n",
    "    return su, mu\n",
    "\n",
    "### stats\n",
    "\n",
    "\n",
    "def apply_cdf(data):\n",
    "    pdf = data / data.sum()\n",
    "    return np.cumsum(pdf) * 100\n",
    "\n",
    "\n",
    "### plotting\n",
    "def plot_hist_cdf_panel(ax0, ax1, hists, bin_edges, cdf_all_regions, color_dict=color_by_region):\n",
    "    ## plot histogram for all data\n",
    "    ax0.bar(bin_edges[:-1], hists, width=np.diff(bin_edges), align='edge', edgecolor='white')\n",
    "\n",
    "    ## plot region-stratified cdf\n",
    "    order = [\"A\", \"H\", \"EC\", \"PHC\", \"Other\"]\n",
    "    #for key, item in cdf_all_regions.items():\n",
    "    for key in order:\n",
    "        item = cdf_all_regions[key]\n",
    "        ax1.plot(bin_edges[:-1], item, label=key, color=color_dict[key], lw=3)\n",
    "\n",
    "def plot_mean(ax0, values):\n",
    "    m = np.nanmean(values)\n",
    "    ax0.axvline(m, ls='--', lw=lw_summary_stat, color=stat_line_color)\n",
    "\n",
    "def sugar(ax0, ax1):\n",
    "    sns.despine(trim=False, ax=ax0)\n",
    "    sns.despine(trim=False, ax=ax1)\n",
    "    ax0.tick_params(labelbottom=False, labelsize=tick_size)\n",
    "    ax1.tick_params(labelbottom=True, labelsize=tick_size)\n",
    "\n",
    "def handle_legend(ax):\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    order = ['A', \"H\", \"EC\", \"PHC\", \"Other\"] \n",
    "    sorted_items = sorted(zip(labels, handles), key=lambda pair: order.index(pair[0]))\n",
    "    labels, handles = zip(*sorted_items)\n",
    "    ax.legend(handles, labels, bbox_to_anchor=(0.35, .8), fontsize=12, markerscale=2, ncols=2, frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "axwidth= 2\n",
    "tickwidth = 3\n",
    "ticksize = 6\n",
    "ticklabelsize= 12\n",
    "small_ticklabelsize = 10\n",
    "labelsize = 15\n",
    "titlesize = 20\n",
    "\n",
    "rc('axes', linewidth=axwidth)\n",
    "rc('xtick.major', width=tickwidth, size=ticksize)\n",
    "rc('xtick', labelsize=ticklabelsize)        \n",
    "rc('ytick.major', width=tickwidth, size=ticksize)\n",
    "rc('ytick', labelsize=ticklabelsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754349c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by_region = {\n",
    "    \"A\": '#E53E24', \n",
    "    \"H\": '#54aead', \n",
    "    \"EC\": \"#D8D806\",\n",
    "    \"PHC\": '#60A02C', \n",
    "    \"Other\": '#FCAF4A',\n",
    "}\n",
    "\n",
    "fig = plt.figure(constrained_layout=False, figsize=(18, 9))\n",
    "gs = fig.add_gridspec(nrows=5, ncols=4,\n",
    "                       height_ratios=[1, 1, 0.2, 1, 1], \n",
    "                       width_ratios=[0.3, 1, 1, 1])\n",
    "\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.6) \n",
    "\n",
    "# single-unit vs multi-units\n",
    "ax0 = fig.add_subplot(gs[0:2, 0])\n",
    "\n",
    "su, mu = count_su_mu(df_units_all)\n",
    "ax0.bar([0,1], [su,mu])\n",
    "ax0.text(0-0.325, su + 10, su, fontsize=10)\n",
    "ax0.text(1-0.335, mu + 10, mu, fontsize=10)\n",
    "ax0.set_title(\"Unit\\ntype\", fontsize=title_size_subplot, pad=10)\n",
    "ax0.set_xticks([0,1])\n",
    "ax0.set_xticklabels([\"SUs\", \"MUs\"], fontsize=label_size)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "sns.despine(ax=ax0)\n",
    "\n",
    "# pyramidal cells vs interneurons\n",
    "ax0 = fig.add_subplot(gs[3:, 0],)\n",
    "pyramdials = (df_units_all[\"cell_type\"] == \"pyramidal\").sum()\n",
    "interneurons = (df_units_all[\"cell_type\"] == \"interneuron\").sum()\n",
    "ax0.bar([0,1], [pyramdials,interneurons],)\n",
    "ax0.text(0-0.325, pyramdials + 10, pyramdials, fontsize=10)\n",
    "ax0.text(1-0.15, interneurons + 10, interneurons, fontsize=10)\n",
    "ax0.set_title(\"Neuron\\ntype\", fontsize=title_size_subplot, pad=10)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "ax0.set_xticks([0,1])\n",
    "ax0.set_xticklabels([\"PCs\", \"INTs\"], fontsize=label_size)\n",
    "\n",
    "sns.despine(ax=ax0)\n",
    "\n",
    "\n",
    "#############################\n",
    "\n",
    "# units per channel\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0:1, 1:2])\n",
    "ax1 = fig.add_subplot(gs[1:2, 1:2], sharex=ax0)\n",
    "bins = np.arange(1, df_channelwise_units[\"channel_count\"].max()+1,)\n",
    "hists, bin_edges, cdf_region_dict = data_units_per_channel(df_channelwise_units, bins=bins)\n",
    "ax0.bar(bin_edges[:-1], hists, width=0.8, align='edge', edgecolor='white')\n",
    "\n",
    "## plot region-stratified cdf\n",
    "for key, item in cdf_region_dict.items():\n",
    "    ax1.plot(bin_edges[:-1], item, label=key, color=color_by_region[key], lw=3)\n",
    "\n",
    "plot_mean(ax0, df_channelwise_units[\"channel_count\"])\n",
    "\n",
    "ax0.set_xticks(bins[1::2])\n",
    "\n",
    "ax0.set_title(\"Units per channel\", fontsize=title_size_subplot)\n",
    "ax0.set_ylabel(\"Nm.\\nchannels\", fontsize=label_size)\n",
    "\n",
    "ax1.set_xlabel(\"Nm. units per channel\", fontsize=label_size)\n",
    "ax1.set_ylabel(\"CDF [%]\", fontsize=label_size)\n",
    "\n",
    "sugar(ax0, ax1)\n",
    "handle_legend(ax1)\n",
    "\n",
    "# firing rate\n",
    "b=30\n",
    "ax0 = fig.add_subplot(gs[0:1, 2:3], )\n",
    "ax1 = fig.add_subplot(gs[1:2, 2:3], sharex=ax0)\n",
    "\n",
    "hists, bin_edges = np.histogram(df_units_all[\"fr_hz\"], b)\n",
    "cdf_region_dict = cdf_regionwise_metrics(df_units_all, \"fr_hz\", b)\n",
    "plot_hist_cdf_panel(ax0, ax1, hists, bin_edges, cdf_region_dict, )\n",
    "plot_mean(ax0, df_units_all[\"fr_hz\"],)\n",
    "\n",
    "ax0.set_title(\"Firing rate\", fontsize=title_size_subplot)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "ax1.set_xlabel(\"FR [Hz]\", fontsize=label_size)\n",
    "ax1.set_ylabel(\"CDF [%]\", fontsize=label_size)\n",
    "sugar(ax0, ax1)\n",
    "\n",
    "# spike peak SNR\n",
    "b=25\n",
    "ax0 = fig.add_subplot(gs[0:1, 3:4])\n",
    "ax1 = fig.add_subplot(gs[1:2, 3:4], sharex=ax0)\n",
    "\n",
    "hists, bin_edges = no_nan_histogram(df_units_all[\"peak_SNR\"], b)\n",
    "cdf_region_dict = cdf_regionwise_metrics(df_units_all, \"peak_SNR\", b)\n",
    "plot_hist_cdf_panel(ax0, ax1, hists, bin_edges, cdf_region_dict, )\n",
    "plot_mean(ax0, df_units_all[\"peak_SNR\"],)\n",
    "\n",
    "ax0.set_title(\"Peak SNR\", fontsize=title_size_subplot)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "ax1.set_xlabel(\"SNR\", fontsize=label_size)\n",
    "ax1.set_ylabel(\"CDF [%]\", fontsize=label_size)\n",
    "sugar(ax0, ax1)\n",
    "\n",
    "\n",
    "# ISI violations\n",
    "ax0 = fig.add_subplot(gs[3:4, 1:2])\n",
    "ax1 = fig.add_subplot(gs[4:, 1:2], sharex=ax0)\n",
    "\n",
    "hists, bin_edges = np.histogram(df_units_all[\"isi_violations\"], b)\n",
    "cdf_region_dict = cdf_regionwise_metrics(df_units_all, \"isi_violations\", b)\n",
    "plot_hist_cdf_panel(ax0, ax1, hists, bin_edges, cdf_region_dict, )\n",
    "m = np.percentile(df_units_all[\"isi_violations\"], 95)\n",
    "ax0.axvline(m, ls=':', lw=lw_summary_stat, color=stat_line_color)\n",
    "ax0.text(m+0.5, ax0.get_ylim()[1]*0.5, f\"95th percentile: {m:.1f}%\", color=stat_line_color)\n",
    "\n",
    "ax0.set_title(\"ISI refractoriness\", fontsize=title_size_subplot)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "\n",
    "ax1.set_xlabel(\"ISIs < 3 ms [%]\", fontsize=label_size)\n",
    "ax1.set_ylabel(\"CDF [%]\", fontsize=label_size)\n",
    "sugar(ax0, ax1)\n",
    "\n",
    "ax0.xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "ax1.xaxis.set_major_locator(mticker.MaxNLocator(integer=True))\n",
    "\n",
    "# CV2\n",
    "ax0 = fig.add_subplot(gs[3:4, 2:3])\n",
    "ax1 = fig.add_subplot(gs[4:, 2:3], sharex=ax0)\n",
    "\n",
    "hists, bin_edges = no_nan_histogram(df_units_all[\"cv2\"], b)\n",
    "cdf_region_dict = cdf_regionwise_metrics(df_units_all, \"cv2\", b)\n",
    "plot_hist_cdf_panel(ax0, ax1, hists, bin_edges, cdf_region_dict, )\n",
    "plot_mean(ax0, df_units_all[\"cv2\"],)\n",
    "\n",
    "ax0.set_title(\"Coefficient of Variation\", fontsize=title_size_subplot)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "ax1.set_xlabel(\"CV2\", fontsize=label_size)\n",
    "ax1.set_ylabel(\"CDF [%]\", fontsize=label_size)\n",
    "sugar(ax0, ax1)\n",
    "\n",
    "\n",
    "# isolation distance\n",
    "ax0 = fig.add_subplot(gs[3:4, 3:4])\n",
    "ax1 = fig.add_subplot(gs[4:, 3:4], sharex=ax0)\n",
    "\n",
    "df_units_all.loc[df_units_all[\"iso_dist\"] > 1e11, \"iso_dist\"] = np.nan # hacky work-around for buggy filter, fix\n",
    "hists, bin_edges = no_nan_histogram(np.log10(df_units_all[\"iso_dist\"]), b)\n",
    "cdf_region_dict = cdf_regionwise_metrics(df_units_all, \"iso_dist\", b, log=True)\n",
    "plot_hist_cdf_panel(ax0, ax1, hists, bin_edges, cdf_region_dict, )\n",
    "plot_mean(ax0, np.log10(df_units_all[\"iso_dist\"]),)\n",
    "\n",
    "ax0.set_title(\"Isolation Distance\", fontsize=title_size_subplot)\n",
    "ax0.set_ylabel(\"Nm. units\", fontsize=label_size)\n",
    "ax1.set_xlabel(r'$\\log_{10}$ $D^{2}$', fontsize=label_size)\n",
    "ax1.set_ylabel(\"CDF [%]\", fontsize=label_size)\n",
    "sugar(ax0, ax1)\n",
    "\n",
    "\n",
    "plt.savefig(panel_save_dir / \"fig_spike_sorting.png\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.savefig(panel_save_dir / \"fig_spike_sorting.svg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Caption Stats\n",
    "\n",
    "# a\n",
    "print(\"a\")\n",
    "print(\"SUs Count:\", su)\n",
    "print(\"MUs Count:\", mu)\n",
    "\n",
    "# b\n",
    "print(\"\\nb\")\n",
    "print(\"PCs count:\", pyramdials)\n",
    "print(\"INTs count:\", interneurons)\n",
    "print(\"Neg. peaks count:\", sum(df_units_all[\"cell_type\"] == \"negative-peak\"))\n",
    "assert sum([pyramdials, interneurons, sum(df_units_all[\"cell_type\"] == \"negative-peak\")]) == su\n",
    "\n",
    "# c\n",
    "print(\"\\nc\")\n",
    "print(\"Mean units per channel:\", np.mean(df_channelwise_units[\"channel_count\"]))\n",
    "print(\"SEM units per channel:\", np.std(df_channelwise_units[\"channel_count\"]) / np.sqrt(len(df_channelwise_units)))  # sem\n",
    "\n",
    "# d\n",
    "print(\"\\nd\")\n",
    "print(\"Mean firing rate [Hz]:\", np.mean(df_units_all[\"fr_hz\"]))\n",
    "print(\"SEM firing rate [Hz]:\", np.std(df_units_all[\"fr_hz\"]) / np.sqrt(len(df_units_all)))  # sem\n",
    "\n",
    "# e\n",
    "print(\"\\ne\")\n",
    "print(\"Mean peak SNR:\", np.nanmean(df_units_all[\"peak_SNR\"]))\n",
    "print(\"SEM peak SNR:\", np.nanstd(df_units_all[\"peak_SNR\"]) / np.sqrt(len(df_units_all) - df_units_all[\"peak_SNR\"].isna().sum()))  # sem\n",
    "\n",
    "# f \n",
    "print(\"\\nf\")\n",
    "print(\"95% percentile ISI violations [%]:\", np.percentile(df_units_all[\"isi_violations\"], 95))\n",
    "print(\"Mean ISI violations [%]:\", np.nanmean(df_units_all[\"isi_violations\"]))\n",
    "print(\"SEM ISI violations [%]:\", np.nanstd(df_units_all[\"isi_violations\"]) / np.sqrt(len(df_units_all) - df_units_all[\"isi_violations\"].isna().sum()))  # sem\n",
    "\n",
    "# g\n",
    "print(\"\\ng\")\n",
    "print(\"Mean CV2:\", np.nanmean(df_units_all[\"cv2\"]))\n",
    "print(\"SEM CV2:\", np.nanstd(df_units_all[\"cv2\"]) / np.sqrt(len(df_units_all) - df_units_all[\"cv2\"].isna().sum()))  #\n",
    "\n",
    "# h\n",
    "print(\"\\nh\")\n",
    "iso_dist = df_units_all[df_units_all[\"iso_dist\"].notna()]\n",
    "print(\"Nm. of isolation distance values:\", len(iso_dist))\n",
    "print(\"Median isolation distance:\", np.median(iso_dist[\"iso_dist\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
